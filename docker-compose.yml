version: "3.9"
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.5
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.3.5
    container_name: kafka
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENERS: INTERNAL://:9092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT

  kafka-topics-generator:
    image: confluentinc/cp-kafka:7.3.5
    container_name: kafka-topics-generator
    depends_on:
      - kafka
    command: bash -c "
      sleep 5s &&
      kafka-topics --create --topic=kafka-predictions --if-not-exists --bootstrap-server=kafka:9092 &&
      sleep 5s &&
      kafka-topics --create --topic=kafka-ckpt --if-not-exists --bootstrap-server=kafka:9092
      "

  greenplum:
    container_name: database
    image: postgres:latest
    ports:
      - "5432:5432"
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    environment:
      - POSTGRES_HOST_AUTH_METHOD=password
      - POSTGRES_PASSWORD=$POSTGRES_PASSWORD
      - POSTGRES_USER=$POSTGRES_USER
      - POSTGRES_DBNAME=$POSTGRES_DBNAME
    restart: always
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "$POSTGRES_USER" ]
      interval: 5s
      timeout: 10s
      retries: 5
    depends_on:
      kafka-topics-generator:
        condition: service_completed_successfully

  fashion-mnist-classifier:
    build: .
    environment:
      - POSTGRES_HOST_AUTH_METHOD=password
      - ANSIBLE_PASSWORD=$ANSIBLE_PASSWORD
    #      - POSTGRES_PASSWORD=$POSTGRES_PASSWORD
    #      - POSTGRES_USER=$POSTGRES_USER
    #      - POSTGRES_DBNAME=$POSTGRES_DBNAME
    #      - POSTGRES_DBHOST=greenplum
    #      - POSTGRES_DBPORT=5432
    command: >
      bash -c "
        coverage run src/unit_tests/test_datasets.py &&
        coverage run src/unit_tests/test_training_results.py &&
        coverage report -m
        "
    image: ${DOCKER_IMAGE_TAG_NAME}
    links:
      - "greenplum:database"
    depends_on:
      greenplum:
        condition: service_healthy
#      kafka-topics-generator:
#        condition: service_completed_successfully